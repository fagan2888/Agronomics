{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Notebook II\n",
    "\n",
    "Georgetown University School for Continuing Studies \n",
    "Georgetown Data Analytics\n",
    "Cohort 10: Agronomics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from scipy import optimize\n",
    "import math\n",
    "import pandas.plotting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import radviz\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from scipy.stats import sem\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Imputer  \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "#from yellowbrick.regressor import PredictionError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Note: Review previous notebooks ( \"Data Ingestion\" and \"Data Wrangling\") to execute the following code\n",
    "\n",
    "Dataframes were created in these notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"5-Merge.csv \" from Data Ingestion and Data Wrangling Notebooks\n",
    "dataset = pd.read_csv('5-MERGE.csv',dtype={'Year':int,'Harvested':int,'Production':int,'Price':float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dataset.County.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dataset.County_Code.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dataset.Commodity_Code.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dataset.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_county = preprocessing.LabelEncoder()\n",
    "\n",
    "#to convert into numbers\n",
    "dataset.County = le_county.fit_transform(dataset.County)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Feature and Target \n",
    "## Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Indicators for Prediction\n",
    "features = ['Year','Harvested','Value','Grow_total_p','Grow_avg_t','Price','Percapita_Personal_Income','House_Price_Index']\n",
    "\n",
    "#What we want to Predict \n",
    "target = 'Yield'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defines indicators and prediction value(s)\n",
    "X = (dataset[features])\n",
    "y = (dataset[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 and L1 Regularization \n",
    "alphas = np.logspace(-10, 0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X=preprocessing.normalize(X)\n",
    "\n",
    "# Create training and test splits \n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "\n",
    "# 20% of the data is used for testing (meaning of test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models \n",
    "1. Linear regression \n",
    "2. ElasticNet \n",
    "3. Lasso CV\n",
    "4. Pipeline \n",
    "5. Random Forest \n",
    "6. AdaBoost\n",
    "7. Bayesian Ridge\n",
    "\n",
    "Install yellowbrick for visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "clf = LinearRegression() \n",
    "scores = cross_validation.cross_val_score(\n",
    "clf, X_train, y_train, cv=5)\n",
    "print(scores) \n",
    "print (\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() / 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression() \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "\n",
    "print(yhat[0:5], model, target)\n",
    "prediction = pd.DataFrame(yhat[0:5], columns=['LinearRegression']).to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Yellowbrick\n",
    "\n",
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(LinearRegression())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "model = ResidualsPlot(LinearRegression())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "model.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ellastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# takes model and fits to training data (20%)\n",
    "model = ElasticNetCV(alphas=alphas) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Y target (prediction) based on the above\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# R2 coefficient\n",
    "r2 = r2_score(y_test, yhat)\n",
    "\n",
    "#Mean Square Error \n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me)) # .3f formates decimal places\n",
    "\n",
    "print(yhat, model, target)\n",
    "prediction = pd.DataFrame(yhat, columns=['ElasticNetCV']).to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(ElasticNetCV())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LassoCV(alphas=alphas) \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(ElasticNetCV())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(2)), \n",
    "    ('lasso', LassoCV(alphas=alphas)),\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.named_steps['lasso'].alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(2)), \n",
    "    ('Elastic', ElasticNetCV\n",
    "(alphas=alphas)),\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.named_steps['Elastic'].alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(Pipeline([\n",
    "    ('poly', PolynomialFeatures(2)), \n",
    "    ('lasso', LassoCV(alphas=alphas)),\n",
    "]))\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "model = ResidualsPlot(LassoCV())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "model.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 5, random_state = 0) \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(RandomForestRegressor())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from IPython.core.display import Image\n",
    "from pandas.compat import StringIO\n",
    "\n",
    "import pydotplus\n",
    "# Visualize tree\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model.estimators_[0], out_file=dot_data)\n",
    "graph=pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "image = graph.write(\"random_network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor() \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(AdaBoostRegressor())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "model = BayesianRidge() \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test) #predicted\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(BayesianRidge())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = svm.SVR()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(svm.SVR())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.Lasso (alpha=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test) #predicted\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(Lasso())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = svm.NuSVR()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(svm.NuSVR())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = svm.LinearSVR()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(svm.LinearSVR())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model= KNeighborsRegressor(n_neighbors=2)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "print(yhat, model, target)\n",
    "prediction = pd.DataFrame(yhat, columns=['predictions']).to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(KNeighborsRegressor())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "print(yhat, model, target)\n",
    "prediction = pd.DataFrame(yhat, columns=['predictions']).to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(Ridge())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a histogram to examine age distribution of the passengers.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(dataset['Yield'], bins = 10, range = (dataset['Yield'].min(),dataset['Yield'].max()))\n",
    "plt.title('Yield distribution')\n",
    "plt.xlabel('Yield')\n",
    "plt.ylabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset[features].hist(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g1 = sns.boxplot(y='Yield', x='Year', data=dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = sns.jointplot(\"Year\", \"Yield\",kind='hex',data= dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Grow_avg_t', y='Grow_total_p', c='Yield',figsize=[20,8])\n",
    "plt.style.use('ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Yield', c='Price',figsize=[20,10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Yield', c='Percapita_Personal_Income',figsize=[20,10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Yield', c='Resident_Population',figsize=[20,10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Annual_t', c='Total_p',figsize=[20,10])\n",
    "plt.style.use('ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Annual_t', c='Total_p',figsize=[20,10])\n",
    "plt.style.use('ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "areas = dataset[['Year','Yield','Price','Grow_total_p','Grow_avg_t','House_Price_Index','Personal_Income']]\n",
    "scatter_matrix(areas, alpha=0.2, figsize=(18,18), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "\n",
    "data1 = dataset.pivot('Yield', 'Year', 'Price')\n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "sns.heatmap(data1, annot=True, fmt='f', linewidths=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('forest-riders.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('forest-riders.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import radviz\n",
    "plt.figure(figsize=(12,12))\n",
    "radviz(dataset, 'Yield')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features.rankd import Rank2D \n",
    "# Instantiate the visualizer with the Covariance ranking algorithm \n",
    "visualizer = Rank2D(features=features, algorithm='covariance')\n",
    "\n",
    "visualizer.fit(X, y)                # Fit the data to the visualizer\n",
    "visualizer.transform(X)             # Transform the data\n",
    "visualizer.poof()    # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Year','Harvested','Value','Grow_total_p','Grow_avg_t','Price']\n",
    "target = 'Yield'\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = (dataset[features])\n",
    "y = (dataset[target])\n",
    "\n",
    "# L2 and L1 Regularization \n",
    "#alphas = np.logspace(-10, 0, 200)\n",
    "\n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y, test_size=0.2,random_state=1)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 10, random_state = 0,max_depth=3) \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "from sklearn import tree\n",
    "from IPython.core.display import Image\n",
    "from pandas.compat import StringIO\n",
    "\n",
    "import pydotplus\n",
    "\n",
    "# Visualize tree\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model.estimators_[5], out_file='tree.dot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

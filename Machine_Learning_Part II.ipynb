{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Notebook II\n",
    "\n",
    "Georgetown University School for Continuing Studies \n",
    "Georgetown Data Analytics\n",
    "Capstone 10: Agronomics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import pylab\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from scipy import optimize\n",
    "import math\n",
    "import pandas.plotting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import radviz\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from scipy.stats import sem\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Imputer  \n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "#from yellowbrick.regressor import PredictionError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Note: Review previous notebooks ( \"Data Ingestion\" and \"Data Wrangling\") to execute the following code\n",
    "\n",
    "Dataframes were created in these notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"5-Merge.csv \" from Data Ingestion and Data Wrangling Notebooks\n",
    "dataset = pd.read_csv('5-MERGE.csv',dtype={'Year':int,'Harvested':int,'Production':int,'Price':float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.County.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dataset.County_Code.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.Commodity_Code.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dataset.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Commodity_Code', 'County_Code', 'County', 'Harvested', 'Yield',\n",
      "       'Production', 'Price', 'Value', 'Grow_total_p', 'Grow_avg_t',\n",
      "       'January_p', 'February_p', 'March_p', 'April_p', 'May_p', 'June_p',\n",
      "       'July_p', 'August_p', 'September_p', 'October_p', 'November_p',\n",
      "       'December_p', 'Total_p', 'January_t', 'February_t', 'March_t',\n",
      "       'April_t', 'May_t', 'June_t', 'July_t', 'August_t', 'September_t',\n",
      "       'October_t', 'November_t', 'December_t', 'Annual_t',\n",
      "       'Percapita_Personal_Income', 'Personal_Income', 'Resident_Population',\n",
      "       'House_Price_Index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 41)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_county = preprocessing.LabelEncoder()\n",
    "\n",
    "#to convert into numbers\n",
    "dataset.County = le_county.fit_transform(dataset.County)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Year  Commodity_Code  County_Code     County      Harvested  \\\n",
      "count    72.000000            72.0    72.000000  72.000000      72.000000   \n",
      "mean   1997.500000        261999.0    24.000000   0.500000   82850.236111   \n",
      "std      10.461196             0.0     5.035088   0.503509   45865.125607   \n",
      "min    1980.000000        261999.0    19.000000   0.000000   23642.000000   \n",
      "25%    1988.750000        261999.0    19.000000   0.000000   46608.250000   \n",
      "50%    1997.500000        261999.0    24.000000   0.500000   72765.000000   \n",
      "75%    2006.250000        261999.0    29.000000   1.000000  104925.000000   \n",
      "max    2015.000000        261999.0    29.000000   1.000000  210000.000000   \n",
      "\n",
      "           Yield     Production        Price         Value  Grow_total_p  \\\n",
      "count  72.000000      72.000000    72.000000  7.200000e+01     72.000000   \n",
      "mean    0.916528   82542.250000  3198.235417  3.122575e+08      4.256653   \n",
      "std     0.241650   59607.525496  1445.119636  3.457742e+08      2.593951   \n",
      "min     0.400000   11700.000000  1250.000000  2.431000e+07      0.282572   \n",
      "25%     0.725000   37950.000000  2071.750000  9.487100e+07      2.370000   \n",
      "50%     0.925000   63900.000000  2930.000000  1.567055e+08      3.655000   \n",
      "75%     1.092500  119600.000000  4000.757500  4.584500e+08      5.243465   \n",
      "max     1.470000  221000.000000  7379.970000  1.453855e+09     12.890000   \n",
      "\n",
      "             ...           August_t  September_t  October_t  November_t  \\\n",
      "count        ...          72.000000    72.000000  72.000000   72.000000   \n",
      "mean         ...          82.183333    77.008333  67.026389   55.048611   \n",
      "std          ...           1.898702     2.611230   2.809390    2.633906   \n",
      "min          ...          77.600000    70.100000  61.400000   48.100000   \n",
      "25%          ...          80.850000    75.675000  64.675000   53.500000   \n",
      "50%          ...          82.350000    77.000000  67.000000   55.400000   \n",
      "75%          ...          83.425000    78.825000  69.025000   56.975000   \n",
      "max          ...          87.000000    81.300000  72.600000   59.900000   \n",
      "\n",
      "       December_t   Annual_t  Percapita_Personal_Income  Personal_Income  \\\n",
      "count   72.000000  72.000000                  72.000000     7.200000e+01   \n",
      "mean    47.458333  65.079167               22006.611111     1.669681e+07   \n",
      "std      2.673171   1.391214                8024.450535     9.209810e+06   \n",
      "min     41.500000  61.600000               10682.000000     4.488004e+06   \n",
      "25%     45.600000  64.200000               15683.000000     9.017645e+06   \n",
      "50%     47.150000  65.000000               19935.500000     1.412190e+07   \n",
      "75%     49.300000  65.650000               29069.500000     2.417455e+07   \n",
      "max     53.700000  69.500000               39124.000000     3.803392e+07   \n",
      "\n",
      "       Resident_Population  House_Price_Index  \n",
      "count            72.000000          72.000000  \n",
      "mean            704.904819         116.128611  \n",
      "std             154.107125          46.993821  \n",
      "min             403.089000          63.370000  \n",
      "25%             588.440250          82.247500  \n",
      "50%             708.389500          96.790000  \n",
      "75%             842.363250         139.895000  \n",
      "max             972.130000         247.190000  \n",
      "\n",
      "[8 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Commodity_Code  County_Code  County  Harvested  Yield  Production  \\\n",
      "0  1980          261999           19       0      23992   0.59       14200   \n",
      "1  1981          261999           19       0      23820   0.75       17900   \n",
      "2  1982          261999           19       0      23642   0.69       16300   \n",
      "3  1983          261999           19       0      24301   0.48       11700   \n",
      "4  1984          261999           19       0      26300   0.94       24700   \n",
      "\n",
      "    Price     Value  Grow_total_p        ...          August_t  September_t  \\\n",
      "0  3000.0  42600000      5.781286        ...              80.7         75.6   \n",
      "1  1500.0  26850000      4.891286        ...              82.9         76.5   \n",
      "2  1800.0  29340000      6.540000        ...              80.4         72.3   \n",
      "3  2300.0  26910000     11.000000        ...              82.1         78.8   \n",
      "4  1800.0  44460000      2.000000        ...              83.5         81.0   \n",
      "\n",
      "   October_t  November_t  December_t  Annual_t  Percapita_Personal_Income  \\\n",
      "0       68.4        54.2        46.8      64.1                    10682.0   \n",
      "1       61.4        55.4        47.7      65.0                    10946.0   \n",
      "2       65.0        51.1        45.4      61.6                    11243.0   \n",
      "3       68.5        54.6        51.1      64.4                    11532.0   \n",
      "4       62.4        53.6        46.5      65.3                    12393.0   \n",
      "\n",
      "   Personal_Income  Resident_Population  House_Price_Index  \n",
      "0        5529740.0              514.621              63.37  \n",
      "1        5789241.0              528.891              68.04  \n",
      "2        6087889.0              541.500              70.15  \n",
      "3        6410514.0              555.873              66.27  \n",
      "4        7089714.0              572.091              66.82  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year  Commodity_Code  County_Code  County  Harvested  Yield  Production  \\\n",
      "67  2011          261999           29       1     147000   1.28      188000   \n",
      "68  2012          261999           29       1     144000   1.13      163000   \n",
      "69  2013          261999           29       1     147000   1.14      168000   \n",
      "70  2014          261999           29       1     199000   1.01      201000   \n",
      "71  2015          261999           29       1     210000   0.94      197000   \n",
      "\n",
      "      Price       Value  Grow_total_p        ...          August_t  \\\n",
      "67  3673.46   690610000      2.680000        ...              83.0   \n",
      "68  4768.75   777306000      3.180000        ...              87.0   \n",
      "69  5492.10   922672000      1.530000        ...              82.7   \n",
      "70  7124.87  1432099000      1.220000        ...              85.0   \n",
      "71  7379.97  1453855000      1.932585        ...              84.0   \n",
      "\n",
      "    September_t  October_t  November_t  December_t  Annual_t  \\\n",
      "67         80.3       67.1        53.3        45.6      64.1   \n",
      "68         81.0       68.2        58.3        50.2      67.0   \n",
      "69         76.9       65.8        58.2        47.7      66.5   \n",
      "70         80.9       71.3        59.4        53.7      69.5   \n",
      "71         80.4       72.6        53.5        47.8      68.0   \n",
      "\n",
      "    Percapita_Personal_Income  Personal_Income  Resident_Population  \\\n",
      "67                    32517.0       27622917.0              849.484   \n",
      "68                    34447.0       29480121.0              855.808   \n",
      "69                    35093.0       30336210.0              864.454   \n",
      "70                    37090.0       32347235.0              872.138   \n",
      "71                    37846.0       33285162.0              879.497   \n",
      "\n",
      "    House_Price_Index  \n",
      "67             121.91  \n",
      "68             125.28  \n",
      "69             142.05  \n",
      "70             161.67  \n",
      "71             169.02  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Feature and Target \n",
    "## Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Indicators for Prediction\n",
    "features = ['Year','Harvested','Value','Grow_total_p','Grow_avg_t','Price','Percapita_Personal_Income','House_Price_Index']\n",
    "\n",
    "#What we want to Predict \n",
    "target = 'Yield'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defines indicators and prediction value(s)\n",
    "X = (dataset[features])\n",
    "y = (dataset[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# L2 and L1 Regularization \n",
    "alphas = np.logspace(-10, 0, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X=preprocessing.normalize(X)\n",
    "\n",
    "# Create training and test splits \n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "\n",
    "# 20% of the data is used for testing (meaning of test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models \n",
    "1. Linear regression \n",
    "2. ElasticNet \n",
    "3. Lasso CV\n",
    "4. Pipeline \n",
    "5. Random Forest \n",
    "6. AdaBoost\n",
    "7. Bayesian Ridge\n",
    "\n",
    "Install yellowbrick for visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.4175214   0.63861698  0.65189448  0.69819657  0.83291287]\n",
      "Accuracy: 0.65 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "clf = LinearRegression() \n",
    "scores = cross_validation.cross_val_score(\n",
    "clf, X_train, y_train, cv=5)\n",
    "print(scores) \n",
    "print (\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() / 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2=0.768 MSE=0.019\n",
      "[ 1.00447365  1.12259297  0.75073438  1.17215866  1.08576894] LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) Yield\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression() \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "\n",
    "print(yhat[0:5], model, target)\n",
    "prediction = pd.DataFrame(yhat[0:5], columns=['LinearRegression']).to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yellowbrick'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-a2c7f7878edc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Install Yellowbrick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregressor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPredictionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# Instantiate the visualizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mvisualizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPredictionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yellowbrick'"
     ]
    }
   ],
   "source": [
    "# Install Yellowbrick\n",
    "\n",
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(LinearRegression())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "model = ResidualsPlot(LinearRegression())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "model.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ellastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes model and fits to training data (20%)\n",
    "model = ElasticNetCV(alphas=alphas) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Y target (prediction) based on the above\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "# R2 coefficient\n",
    "r2 = r2_score(y_test, yhat)\n",
    "\n",
    "#Mean Square Error \n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me)) # .3f formates decimal places\n",
    "\n",
    "print(yhat, model, target)\n",
    "prediction = pd.DataFrame(yhat, columns=['ElasticNetCV']).to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(ElasticNetCV())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LassoCV(alphas=alphas) \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(ElasticNetCV())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(2)), \n",
    "    ('lasso', LassoCV(alphas=alphas)),\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.named_steps['lasso'].alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(2)), \n",
    "    ('Elastic', ElasticNetCV\n",
    "(alphas=alphas)),\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f} alpha={:0.3f}\".format(r2,me, model.named_steps['Elastic'].alpha_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(Pipeline([\n",
    "    ('poly', PolynomialFeatures(2)), \n",
    "    ('lasso', LassoCV(alphas=alphas)),\n",
    "]))\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import ResidualsPlot\n",
    "model = ResidualsPlot(LassoCV())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)\n",
    "model.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 5, random_state = 0) \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(RandomForestRegressor())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from IPython.core.display import Image\n",
    "from pandas.compat import StringIO\n",
    "\n",
    "import pydotplus\n",
    "# Visualize tree\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model.estimators_[0], out_file=dot_data)\n",
    "graph=pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "image = graph.write(\"random_network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "model = AdaBoostRegressor() \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(AdaBoostRegressor())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesianRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "model = BayesianRidge() \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test) #predicted\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(BayesianRidge())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVR()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(svm.SVR())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "model = linear_model.Lasso (alpha=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test) #predicted\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(Lasso())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.NuSVR()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(svm.NuSVR())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.LinearSVR()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(svm.LinearSVR())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Neighbors Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "model= KNeighborsRegressor(n_neighbors=2)\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "print(yhat, model, target)\n",
    "prediction = pd.DataFrame(yhat, columns=['predictions']).to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(KNeighborsRegressor())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "print(yhat, model, target)\n",
    "prediction = pd.DataFrame(yhat, columns=['predictions']).to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from yellowbrick.regressor import PredictionError\n",
    "# Instantiate the visualizer\n",
    "visualizer = PredictionError(Ridge())\n",
    "# Fit\n",
    "visualizer.fit(X_train, y_train)\n",
    "# Score and visualize\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a histogram to examine age distribution of the passengers.\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.hist(dataset['Yield'], bins = 10, range = (dataset['Yield'].min(),dataset['Yield'].max()))\n",
    "plt.title('Yield distribution')\n",
    "plt.xlabel('Yield')\n",
    "plt.ylabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset[features].hist(figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = sns.boxplot(y='Yield', x='Year', data=dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = sns.jointplot(\"Year\", \"Yield\",kind='hex',data= dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Grow_avg_t', y='Grow_total_p', c='Yield',figsize=[20,8])\n",
    "plt.style.use('ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Yield', c='Price',figsize=[20,10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Yield', c='Percapita_Personal_Income',figsize=[20,10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Yield', c='Resident_Population',figsize=[20,10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Annual_t', c='Total_p',figsize=[20,10])\n",
    "plt.style.use('ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.plot(kind='scatter', x='Year', y='Annual_t', c='Total_p',figsize=[20,10])\n",
    "plt.style.use('ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import scatter_matrix\n",
    "areas = dataset[['Year','Yield','Price','Grow_total_p','Grow_avg_t','House_Price_Index','Personal_Income']]\n",
    "scatter_matrix(areas, alpha=0.2, figsize=(18,18), diagonal='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "\n",
    "\n",
    "data1 = dataset.pivot('Yield', 'Year', 'Price')\n",
    "\n",
    "# Draw a heatmap with the numeric values in each cell\n",
    "sns.heatmap(data1, annot=True, fmt='f', linewidths=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('forest-riders.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('forest-riders.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas.tools.plotting import radviz\n",
    "plt.figure(figsize=(12,12))\n",
    "radviz(dataset, 'Yield')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.features.rankd import Rank2D \n",
    "# Instantiate the visualizer with the Covariance ranking algorithm \n",
    "visualizer = Rank2D(features=features, algorithm='covariance')\n",
    "\n",
    "visualizer.fit(X, y)                # Fit the data to the visualizer\n",
    "visualizer.transform(X)             # Transform the data\n",
    "visualizer.poof()    # Draw/show/poof the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['Year','Harvested','Value','Grow_total_p','Grow_avg_t','Price']\n",
    "target = 'Yield'\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = (dataset[features])\n",
    "y = (dataset[target])\n",
    "\n",
    "# L2 and L1 Regularization \n",
    "#alphas = np.logspace(-10, 0, 200)\n",
    "\n",
    "X_train, X_test, y_train, y_test = cv.train_test_split(X, y, test_size=0.2,random_state=1)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 10, random_state = 0,max_depth=3) \n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "r2 = r2_score(y_test, yhat)\n",
    "me = mse(y_test, yhat)\n",
    "print(\"r2={:0.3f} MSE={:0.3f}\".format(r2,me))\n",
    "\n",
    "from sklearn import tree\n",
    "from IPython.core.display import Image\n",
    "from pandas.compat import StringIO\n",
    "\n",
    "import pydotplus\n",
    "\n",
    "# Visualize tree\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model.estimators_[5], out_file='tree.dot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
